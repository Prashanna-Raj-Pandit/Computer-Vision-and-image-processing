{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade=cv2.CascadeClassifier('Computer-Vision-with-Python/DATA/haarcascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "    center_x=0\n",
    "    center_y=0\n",
    "    face_img=img.copy()\n",
    "    face_rects=face_cascade.detectMultiScale(face_img)\n",
    "    \n",
    "    for(x,y,w,h) in face_rects:\n",
    "        cv2.rectangle(face_img,(x,y),(x+w,y+h),(255,255,255),10)\n",
    "    \n",
    "    for (x, y, w, h) in face_rects:\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "    return face_img,center_x,center_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-136fd148797f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcenter_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcenter_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdetect_face\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline_end\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-7a13b5654082>\u001b[0m in \u001b[0;36mdetect_face\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcenter_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcenter_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mface_img\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mface_rects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "line_start = (250, 100)\n",
    "line_end = (250, 400)\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read(0)\n",
    "    \n",
    "    frame,center_x,center_y=detect_face(frame)\n",
    "    cv2.line(frame, line_start, line_end, (0, 0, 255), 2)\n",
    "    \n",
    "    if line_start[0] <= center_x <= line_end[0] and line_start[1] <= center_y <= line_end[1]:\n",
    "        crossing=True\n",
    "        winsound.Beep(700,400)\n",
    "        print(crossing)\n",
    "         # Object has crossed the line, draw a circle around it   \n",
    "        cv2.circle(frame, (center_x, center_y), 50, (0, 255, 0), -1)\n",
    "    cv2.imshow('frame',frame)\n",
    "    k=cv2.waitKey(1)\n",
    "    if k==27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20415b23b00>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Define the boundary shape (a rectangle in this case)\n",
    "shape = (100, 50, 100, 100)  # (x, y, width, height)\n",
    "\n",
    "# Create a blank image\n",
    "image = np.zeros((300, 300, 3), np.uint8)\n",
    "\n",
    "# Draw the rectangle on the image\n",
    "cv2.rectangle(image, (shape[0], shape[1]), (shape[0]+shape[2], shape[1]+shape[3]), (255, 255, 255), -1)\n",
    "\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted state: [0.6875 0.    ]\n",
      "Predicted covariance: [[0.34375 0.     ]\n",
      " [0.      0.34375]]\n",
      "Predicted state: [1.30463576 0.        ]\n",
      "Predicted covariance: [[0.23509934 0.        ]\n",
      " [0.         0.23509934]]\n",
      "Predicted state: [1.98493259 0.        ]\n",
      "Predicted covariance: [[0.20063442 0.        ]\n",
      " [0.         0.20063442]]\n",
      "Predicted state: [2.74158082 0.        ]\n",
      "Predicted covariance: [[0.18774762 0.        ]\n",
      " [0.         0.18774762]]\n",
      "Predicted state: [3.5665338 0.       ]\n",
      "Predicted covariance: [[0.18263947 0.        ]\n",
      " [0.         0.18263947]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KalmanFilter:\n",
    "    def __init__(self, initial_state, initial_covariance, transition_matrix, process_noise_covariance, measurement_matrix, measurement_noise_covariance):\n",
    "        self.state = initial_state\n",
    "        self.covariance = initial_covariance\n",
    "        self.transition_matrix = transition_matrix\n",
    "        self.process_noise_covariance = process_noise_covariance\n",
    "        self.measurement_matrix = measurement_matrix\n",
    "        self.measurement_noise_covariance = measurement_noise_covariance\n",
    "\n",
    "    def predict(self):\n",
    "        self.state = np.dot(self.transition_matrix, self.state)\n",
    "        self.covariance = np.dot(self.transition_matrix, np.dot(self.covariance, self.transition_matrix.T)) + self.process_noise_covariance\n",
    "\n",
    "    def update(self, measurement):\n",
    "        innovation = measurement - np.dot(self.measurement_matrix, self.state)\n",
    "        innovation_covariance = np.dot(self.measurement_matrix, np.dot(self.covariance, self.measurement_matrix.T)) + self.measurement_noise_covariance\n",
    "        kalman_gain = np.dot(self.covariance, np.dot(self.measurement_matrix.T, np.linalg.inv(innovation_covariance)))\n",
    "        self.state = self.state + np.dot(kalman_gain, innovation)\n",
    "        self.covariance = self.covariance - np.dot(kalman_gain, np.dot(self.measurement_matrix, self.covariance))\n",
    "\n",
    "# Example usage\n",
    "kf = KalmanFilter(initial_state=[0, 0], initial_covariance=np.eye(2), transition_matrix=np.eye(2), process_noise_covariance=np.eye(2) * 0.1, measurement_matrix=np.eye(2), measurement_noise_covariance=np.eye(2) * 0.5)\n",
    "\n",
    "measurements = [[1, 0], [2, 0], [3, 0], [4, 0], [5, 0]]\n",
    "\n",
    "for measurement in measurements:\n",
    "    kf.predict()\n",
    "    kf.update(measurement)\n",
    "    print(f\"Predicted state: {kf.state}\")\n",
    "    print(f\"Predicted covariance: {kf.covariance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 506, 42, 67)\n",
      "58\n",
      "116\n",
      "150\n",
      "165\n",
      "173\n",
      "173\n",
      "179\n",
      "185\n",
      "188\n",
      "199\n",
      "203\n",
      "206\n",
      "206\n",
      "208\n",
      "206\n",
      "208\n",
      "206\n",
      "206\n",
      "210\n",
      "212\n",
      "223\n",
      "224\n",
      "224\n",
      "224\n",
      "224\n",
      "224\n",
      "224\n",
      "224\n",
      "224\n",
      "224\n",
      "224\n",
      "224\n",
      "224\n",
      "224\n",
      "228\n",
      "228\n",
      "232\n",
      "238\n",
      "241\n",
      "249\n",
      "246\n",
      "243\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "245\n",
      "243\n",
      "244\n",
      "246\n",
      "247\n",
      "247\n",
      "244\n",
      "244\n",
      "248\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import winsound\n",
    "import time\n",
    "\n",
    "line_start = (25, 250)\n",
    "line_end = (400, 250)\n",
    "\n",
    "center_x=0\n",
    "center_y=0\n",
    "red=False \n",
    "\n",
    "# video1 = cv2.VideoCapture(\"traffic_light_cop.mp4\")\n",
    "video1 = cv2.VideoCapture(\"test_video2.mp4\")\n",
    "video2=cv2.VideoCapture(\"ramp.mp4\")\n",
    "video3=cv2.VideoCapture(\"parking.mp4\")\n",
    "video4=cv2.VideoCapture(\"uturn.mp4\")\n",
    "video5=cv2.VideoCapture(\"traffic_light_cop.mp4\")\n",
    "\n",
    "ret1, eight = video1.read()\n",
    "ret2,ramp=video2.read()\n",
    "ret3,parking=video3.read()\n",
    "ret4,u_turn=video4.read()\n",
    "ret5,t_light=video5.read()\n",
    "\n",
    "eight=cv2.resize(eight,(368,640))\n",
    "ramp=cv2.resize(ramp,(368,640))\n",
    "parking=cv2.resize(parking,(500,250))\n",
    "u_turn=cv2.resize(u_turn,(400,640))\n",
    "t_light=cv2.resize(t_light,(368,640))\n",
    "\n",
    "# np.rot90(frame, k=1, axes=(0, 1))\n",
    "\n",
    "\n",
    "# Select the region of interest (ROI) for tracking\n",
    "roi = cv2.selectROI(eight)\n",
    "print(roi)\n",
    "track_img=eight.copy()\n",
    "# roi=(185, 506, 40, 73)\n",
    "roi1=(143, 457, 100, 160)\n",
    "\n",
    "# Create a mask for the ROI\n",
    "mask1 = np.zeros_like(eight)\n",
    "mask1[roi[1]:roi[1]+roi[3], roi[0]:roi[0]+roi[2]] = 255\n",
    "track_img[roi1[1]:roi1[1]+roi1[3], roi1[0]:roi1[0]+roi1[2]]=0\n",
    "\n",
    "#cv2.imshow(\"track image\",track_img)\n",
    "\n",
    "\n",
    "# Set up the CAMShift tracker\n",
    "tracker = cv2.TrackerCSRT_create()\n",
    "tracker.init(eight, roi)   #initializing the tracker with the bounding box coordinates\n",
    "\n",
    "\n",
    "\n",
    "def ramp_track():\n",
    "    while True:\n",
    "            \n",
    "        ret2,ramp=video2.read()\n",
    "\n",
    "        if not ret2:\n",
    "            break\n",
    "        ramp=cv2.resize(ramp,(368,640))\n",
    "        time.sleep(1/20)\n",
    "        cv2.imshow(\"ramp\", ramp)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    video2.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def parking_track():\n",
    "    while True:\n",
    "        ret3,parking=video3.read()\n",
    "        \n",
    "        if not ret3:\n",
    "            break\n",
    "        parking=cv2.resize(parking,(500,250))\n",
    "        time.sleep(1/20)\n",
    "        park_cpy=parking.copy()\n",
    "        \n",
    "        blur = cv2.GaussianBlur(park_cpy, (5, 5), 0)\n",
    "        #rec,thresh1=cv2.threshold(frame,127,255,cv2.THRESH_BINARY_INV)\n",
    "        imgHSV=cv2.cvtColor(blur,cv2.COLOR_BGR2HSV)\n",
    "        lower=np.array([4,22,16])\n",
    "        upper=np.array([100,249,255])\n",
    "        mask=cv2.inRange(imgHSV,lower,upper)\n",
    "        cv2.imshow(\"Mask\",mask)\n",
    "\n",
    "        blur1 = cv2.GaussianBlur(parking, (5, 5), 0)\n",
    "        carHSV=cv2.cvtColor(blur1,cv2.COLOR_BGR2HSV)\n",
    "        car_lower=np.array([0,55,153])\n",
    "        car_upper=np.array([24,255,255])\n",
    "        car_mask=cv2.inRange(carHSV,car_lower,car_upper)\n",
    "        cv2.imshow(\"car mask\",car_mask)\n",
    "        \n",
    "        result_img=cv2.bitwise_and(parking,parking,mask=mask)\n",
    "        cv2.imshow(\"result\",result_img)\n",
    "        \n",
    "        intersection = cv2.bitwise_and(mask,car_mask)\n",
    "        \n",
    "        num_white_pixels = cv2.countNonZero(intersection)\n",
    "        cv2.imshow(\"Parking Img\",parking)\n",
    "        if num_white_pixels>50:\n",
    "            print(num_white_pixels)\n",
    "            winsound.Beep(700,400)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    video3.release()\n",
    "    cv2.destroyAllWindows()\n",
    "            \n",
    "\n",
    "        \n",
    "def u_turn_track():\n",
    "    while True:\n",
    "        ret4,u_turn=video4.read()\n",
    "        \n",
    "        if not ret4:\n",
    "            break\n",
    "        \n",
    "        u_turn=cv2.resize(u_turn,(400,640))\n",
    "        time.sleep(1/20)\n",
    "        \n",
    "        blur = cv2.GaussianBlur(u_turn, (5, 5), 0)\n",
    "        #rec,thresh1=cv2.threshold(frame,127,255,cv2.THRESH_BINARY_INV)\n",
    "        imgHSV=cv2.cvtColor(blur,cv2.COLOR_BGR2HSV)\n",
    "        lower=np.array([4,52,16])\n",
    "        upper=np.array([100,249,255])\n",
    "        mask=cv2.inRange(imgHSV,lower,upper)\n",
    "\n",
    "        blur1 = cv2.GaussianBlur(u_turn, (5, 5), 0)\n",
    "        carHSV=cv2.cvtColor(blur1,cv2.COLOR_BGR2HSV)\n",
    "        car_lower=np.array([0,55,153])\n",
    "        car_upper=np.array([24,255,255])\n",
    "        car_mask=cv2.inRange(carHSV,car_lower,car_upper)\n",
    "        \n",
    "        cv2.imshow(\"Mask\",mask)\n",
    "        cv2.imshow(\"car mask\",car_mask)\n",
    "        cv2.imshow(\"U Turn Track\",u_turn)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    video4.release()\n",
    "    cv2.destroyAllWindows()\n",
    "        \n",
    "      \n",
    "   \n",
    "    \n",
    "def traffic_light():\n",
    "    while True:\n",
    "        ret5,t_light=video5.read()\n",
    "        \n",
    "        if not ret5:\n",
    "            break\n",
    "            \n",
    "        t_light=cv2.resize(t_light,(368,640))\n",
    "        time.sleep(1/4)\n",
    "        cv2.line(t_light, line_start, line_end, (0, 0, 255), 2)\n",
    "        \n",
    "        #cropped traffic light\n",
    "        img2=t_light[21:31,254:258]\n",
    "        img2=cv2.resize(img2,(320,184))\n",
    "        cv2.imshow(\"cropped\",img2)\n",
    "        \n",
    "        imgHSV=cv2.cvtColor(t_light,cv2.COLOR_BGR2HSV)\n",
    "        lower=np.array([0,179,171])\n",
    "        upper=np.array([255,255,255])\n",
    "        mask=cv2.inRange(imgHSV,lower,upper)\n",
    "        mask=cv2.resize(mask,(368,640))\n",
    "        cv2.imshow(\"mask\",mask)\n",
    "        result_img=cv2.bitwise_and(t_light,t_light,mask=mask)\n",
    "        cv2.imshow(\"result image\",result_img)\n",
    "        \n",
    "        circle_at_center=np.zeros_like(t_light)\n",
    "        \n",
    "        success, roi = tracker.update(t_light)\n",
    "        \n",
    "        if success:\n",
    "            x, y, w, h = [int(i) for i in roi]\n",
    "        \n",
    "            center_x = x + w // 2\n",
    "            center_y = y + h // 2\n",
    "            cv2.rectangle(t_light, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            cv2.circle(circle_at_center, (center_x, center_y),20, (255, 255, 255), -1)\n",
    "            circle_at_center=cv2.cvtColor(circle_at_center,cv2.COLOR_BGR2GRAY)  #to remove the color channels\n",
    "            cv2.imshow(\"circle at center\",circle_at_center)\n",
    "            \n",
    "#             if line_start[0] <= center_x <= line_end[0] and line_start[1] <= center_y <= line_end[1]:\n",
    "#                 crossing=True\n",
    "#                 winsound.Beep(700,400)\n",
    "#                 print(crossing)\n",
    "#                  # Object has crossed the line, draw a circle around it   \n",
    "#                 cv2.circle(eight, (center_x, center_y), 50, (0, 255, 0), -1)\n",
    "\n",
    "            R =img2[125,150,2] #BGR format\n",
    "            if R>=200:\n",
    "                intersection = cv2.bitwise_and(mask,circle_at_center)\n",
    "                num_white_pixels = cv2.countNonZero(intersection)\n",
    "                if num_white_pixels>10:\n",
    "                    print(num_white_pixels)\n",
    "                    winsound.Beep(700,400)\n",
    "            \n",
    "#                 winsound.Beep(700,400)\n",
    "        #         winsound.PlaySound('alert.WAV', winsound.SND_ASYNC)\n",
    "                    red=True\n",
    "                    print(\"Fail\")\n",
    "        cv2.imshow(\"traffic light\",t_light)\n",
    "        k=cv2.waitKey(1) &0xFF\n",
    "        if k==27:\n",
    "            break\n",
    "\n",
    "        \n",
    "        \n",
    "    video5.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "while True:\n",
    "   \n",
    "    ret1, eight = video1.read()\n",
    "    \n",
    "    \n",
    "    if not ret1:\n",
    "        video1.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        u_turn_track()\n",
    "        roi=(120, 376, 98, 129)\n",
    "#         roi=(143, 296,81,89)\n",
    "        tracker = cv2.TrackerCSRT_create()\n",
    "        tracker.init(t_light, roi)\n",
    "        traffic_light()\n",
    "        \n",
    "        ramp_track()\n",
    "        parking_track()\n",
    "        \n",
    "        break\n",
    "    \n",
    "#     np.rot90(frame, k=1, axes=(0, 1))\n",
    "    \n",
    "#     time.sleep(1/20)\n",
    "    eight=cv2.resize(eight,(368,640))\n",
    "    copied=eight.copy()\n",
    "   \n",
    "    blur = cv2.GaussianBlur(track_img, (5, 5), 0)\n",
    "    #rec,thresh1=cv2.threshold(frame,127,255,cv2.THRESH_BINARY_INV)\n",
    "    imgHSV=cv2.cvtColor(blur,cv2.COLOR_BGR2HSV)\n",
    "    lower=np.array([4,52,16])\n",
    "    upper=np.array([100,249,255])\n",
    "    mask=cv2.inRange(imgHSV,lower,upper)\n",
    "    \n",
    "    blur1 = cv2.GaussianBlur(eight, (5, 5), 0)\n",
    "    carHSV=cv2.cvtColor(blur1,cv2.COLOR_BGR2HSV)\n",
    "    car_lower=np.array([0,55,153])\n",
    "    car_upper=np.array([24,255,255])\n",
    "    car_mask=cv2.inRange(carHSV,car_lower,car_upper)\n",
    "    \n",
    "    \n",
    "    # Update the tracker and get the new ROI\n",
    "    success, roi = tracker.update(eight)\n",
    "\n",
    "    circle_at_center=np.zeros_like(copied)\n",
    "    \n",
    "    if success:\n",
    "        cv2.imshow(\"mask\",mask)\n",
    "        result_img=cv2.bitwise_and(eight,eight,mask=mask)\n",
    "        car_img=cv2.bitwise_and(eight,eight,mask=car_mask)\n",
    "        cv2.imshow(\"car Mask\",car_mask)\n",
    "        cv2.imshow(\"result_img\",result_img)\n",
    "        \n",
    "        cv2.line(mask, line_start, line_end, (0, 0, 255), 2)\n",
    "        \n",
    "        # Unpack the ROI tuple \n",
    "        x, y, w, h = [int(i) for i in roi]\n",
    "        \n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        cv2.rectangle(eight, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        cv2.circle(circle_at_center, (center_x, center_y),30, (255, 255, 255), -1)\n",
    "        circle_at_center=cv2.cvtColor(circle_at_center,cv2.COLOR_BGR2GRAY)  #to remove the color channels\n",
    "        cv2.imshow(\"circle at center\",circle_at_center)\n",
    "        \n",
    "        mask1 = np.zeros_like(eight)  #to update the mask in every frame\n",
    "        cv2.rectangle(mask1, (x, y), (x+w, y+h), (255, 255, 255), -1)\n",
    "        gray_mask1=cv2.cvtColor(mask1,cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow(\"bounding box mask\",gray_mask1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        intersection = cv2.bitwise_and(mask,circle_at_center)\n",
    "        \n",
    "        num_white_pixels = cv2.countNonZero(intersection)\n",
    "        \n",
    "        if num_white_pixels>45:\n",
    "            print(num_white_pixels)\n",
    "            winsound.Beep(700,400)\n",
    "        \n",
    "        if line_start[0] <= center_x <= line_end[0] and line_start[1] <= center_y <= line_end[1]:\n",
    "            crossing=True\n",
    "            winsound.Beep(700,400)\n",
    "            print(crossing)\n",
    "             # Object has crossed the line, draw a circle around it   \n",
    "            cv2.circle(eight, (center_x, center_y), 50, (0, 255, 0), -1)\n",
    "    \n",
    "    cv2.imshow(\"Tracking\", eight)\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        \n",
    "        break\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 368, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_light.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 368)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_mask1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) C:\\Miniconda3\\conda-bld\\opencv-suite_1534379934306\\work\\modules\\core\\src\\count_non_zero.cpp:362: error: (-215:Assertion failed) cn == 1 in function 'cv::countNonZero'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-e69bc524bf3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Count the number of white pixels in the intersection image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mnum_white_pixels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountNonZero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# Check if the ROI and the bounding box intersect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.2) C:\\Miniconda3\\conda-bld\\opencv-suite_1534379934306\\work\\modules\\core\\src\\count_non_zero.cpp:362: error: (-215:Assertion failed) cn == 1 in function 'cv::countNonZero'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the ROI and the bounding box\n",
    "roi = (10, 10, 50, 50)  # top-left x, top-left y, width, height\n",
    "bbox = (20, 20, 40, 40)  # top-left x, top-left y, width, height\n",
    "\n",
    "# Create a black image with the same size as the frame\n",
    "frame = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "\n",
    "# Draw the ROI and the bounding box on the frame\n",
    "cv2.rectangle(frame, roi[:2], (roi[0] + roi[2], roi[1] + roi[3]), (255, 0, 0), 2)\n",
    "cv2.rectangle(frame, bbox[:2], (bbox[0] + bbox[2], bbox[1] + bbox[3]), (0, 255, 0), 2)\n",
    "\n",
    "# Create a mask for the ROI\n",
    "mask = np.zeros_like(frame)\n",
    "cv2.rectangle(mask, roi[:2], (roi[0] + roi[2], roi[1] + roi[3]), (255, 255, 255), -1)\n",
    "\n",
    "# Create a mask for the bounding box\n",
    "mask2 = np.zeros_like(frame)\n",
    "cv2.rectangle(mask2, bbox[:2], (bbox[0] + bbox[2], bbox[1] + bbox[3]), (255, 255, 255), -1)\n",
    "\n",
    "# Compute the intersection between the ROI and the bounding box\n",
    "intersection = cv2.bitwise_and(mask, mask2)\n",
    "\n",
    "# Count the number of white pixels in the intersection image\n",
    "num_white_pixels = cv2.countNonZero(intersection)\n",
    "\n",
    "# Check if the ROI and the bounding box intersect\n",
    "if num_white_pixels > 0:\n",
    "    print('ROI and bounding box intersect')\n",
    "else:\n",
    "    print('ROI and bounding box do not intersect')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) C:\\Miniconda3\\conda-bld\\opencv-suite_1534379934306\\work\\modules\\core\\src\\arithm.cpp:225: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function 'cv::binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0dda2948a7e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Compute the intersection between the ROI and the bounding box\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mintersection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Count the number of white pixels in the intersection image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.2) C:\\Miniconda3\\conda-bld\\opencv-suite_1534379934306\\work\\modules\\core\\src\\arithm.cpp:225: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and type), nor 'array op scalar', nor 'scalar op array' in function 'cv::binary_op'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the bounding box\n",
    "bbox = (20, 20, 40, 40)  # top-left x, top-left y, width, height\n",
    "\n",
    "# Load the frame and create the ROI mask\n",
    "frame = cv2.imread('test.PNG')\n",
    "\n",
    "imgHSV=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "lower=np.array([4,52,16])\n",
    "upper=np.array([100,249,255])\n",
    "mask=cv2.inRange(imgHSV,lower,upper)\n",
    "\n",
    "roi_mask=mask.copy()\n",
    "#roi_mask = cv2.imread('roi_mask.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Draw the bounding box on the frame\n",
    "cv2.rectangle(frame, bbox[:2], (bbox[0] + bbox[2], bbox[1] + bbox[3]), (0, 255, 0), 2)\n",
    "\n",
    "# Create a mask for the bounding box\n",
    "mask = np.zeros_like(frame)\n",
    "cv2.rectangle(mask, bbox[:2], (bbox[0] + bbox[2], bbox[1] + bbox[3]), (255, 255, 255), -1)\n",
    "\n",
    "# Compute the intersection between the ROI and the bounding box\n",
    "intersection = cv2.bitwise_and(roi_mask, mask)\n",
    "\n",
    "# Count the number of white pixels in the intersection image\n",
    "num_white_pixels = cv2.countNonZero(intersection)\n",
    "\n",
    "# Check if the ROI and the bounding box intersect\n",
    "if num_white_pixels > 0:\n",
    "    print('ROI and bounding box intersect')\n",
    "else:\n",
    "    print('ROI and bounding box do not intersect')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
